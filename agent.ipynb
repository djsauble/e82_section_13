{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='agents'></a>\n",
    "\n",
    "<a href='#top'>Back to top</a>\n",
    "\n",
    "## AI agents\n",
    "-----\n",
    "\n",
    "Agents extend the functionality of what LLMs can do. A typical LLM is capable of generating text based on its context and training data. In addition, an agent can choose to take action using tools that are made available to it.\n",
    "\n",
    "The new [OpenAI Assistants API](https://platform.openai.com/docs/assistants/overview) provides the ability to write an agent that has access to OpenAI-hosted tools, like Code Interpreter and Knowledge Retrieval, or to custom tools that you define as functions.\n",
    "\n",
    "Traditional LLMs are pretty bad at math because of how they work, but an agent can be instructed to write code to solve math problems and thus produce much better results than a typical LLM. Let's go through a simple example that demonstrates how this works.\n",
    "\n",
    "First, let's show how even the latest GPT-4 Turbo fails to solve basic math problems correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI # pip install openai\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def query_gpt4(prompt):  \n",
    "  response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4-1106-preview\", # This is the id of the GPT-4 Turbo model\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the multiplication of 5.423 and 29.4102, multiply these two numbers together:\n",
      "\n",
      "5.423 * 29.4102 = 159.5142466\n"
     ]
    }
   ],
   "source": [
    "# Correct answer is 159.4915146\n",
    "prompt = \"5.423 * 29.4102 = ?\"\n",
    "print(query_gpt4(prompt))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's close but not quite right, and errors tend to compound, so as you get further into a math-focused chat session, the errors are going to get progressively worse.\n",
    "\n",
    "To solve this, we can use the ChatGPT Assistants API to instruct GPT to use Code Interpreter to write and run Python code in a sandboxed execution environment to get more accurate answers to these sorts of questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = openai_client.beta.assistants.create(\n",
    "  instructions=\"You are a personal math tutor. When asked a math question, write and run code to answer the question.\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a thread with a message containing the math problem you want ChatGPT to solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = openai_client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"5.423 * 29.4102 = ?\"\n",
    "    }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the thread to get the agent's response to your prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = openai_client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = openai_client.beta.threads.messages.list(thread_id=thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The product of 5.423 and 29.4102 is approximately 159.4915146.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.data[0].content[0].text.value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is exactly the correct answer! To recap:\n",
    "\n",
    "* Original prompt: 5.423 * 29.4102 = ?\n",
    "* Correct answer: 159.4915146\n",
    "* Answer w/o agent: 159.5142466 (wrong)\n",
    "* Answer w/ agent: 159.4915146 (right!)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
